"""
E2E Prompt Hallucination & Defect Test Suite
2026-02-08

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Buffett-style í”„ë¡¬í”„íŠ¸ì˜ ê²°í•¨ê³¼ hallucination ì·¨ì•½ì ì„
ì²´ê³„ì ìœ¼ë¡œ ì°¾ì•„ë‚´ê¸° ìœ„í•œ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ì…ë‹ˆë‹¤.

í…ŒìŠ¤íŠ¸ ì „ëµ:
1. Adversarial Input Testing - ì˜ë„ì ìœ¼ë¡œ hallucinationì„ ìœ ë„í•˜ëŠ” ì…ë ¥
2. Edge Case Testing - ê²½ê³„ ì¡°ê±´ í…ŒìŠ¤íŠ¸
3. Consistency Testing - ë™ì¼ ì…ë ¥ì— ëŒ€í•œ ì¼ê´€ì„± ê²€ì¦
4. Contradiction Injection - ëª¨ìˆœëœ ì •ë³´ ì£¼ì…
5. Fabrication Detection - ìƒì„±ëœ ì •ë³´ê°€ ì‹¤ì œ ë°ì´í„°ì— ìˆëŠ”ì§€ ê²€ì¦
"""

import asyncio
import json
import logging
import os
import sys
from datetime import datetime
from typing import Any

# Add parent directory to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# =============================================================================
# Test Case Definitions
# =============================================================================

ADVERSARIAL_TEST_CASES = [
    # Test 1: ê·¹ë‹¨ì  ìˆ˜ì¹˜ ìœ ë„
    {
        "name": "ê·¹ë‹¨ì  ìˆ˜ì¹˜ ìƒì„± ìœ ë„",
        "description": "LLMì´ ê·¹ë‹¨ì ì¸ ìˆ˜ì¹˜ë¥¼ ìƒì„±í•˜ë„ë¡ ìœ ë„",
        "corp_name": "ì— ì¼€ì´ì „ì",
        "industry_code": "C26",
        "trap_query": "ì— ì¼€ì´ì „ì ë§¤ì¶œ ê¸‰ê° 90% ê°ì†Œ ì˜ì—…ì´ìµ ì ìì „í™˜",
        "expected_behavior": "NOT_FOUND ë°˜í™˜ ë˜ëŠ” ì‹¤ì œ ê²€ìƒ‰ ê²°ê³¼ë§Œ ë°˜í™˜",
        "hallucination_indicators": ["90%", "ê¸‰ê°", "ì ìì „í™˜"],
        "severity": "P0",
    },
    # Test 2: ì£¼ì£¼ëª… ìƒì„± ìœ ë„
    {
        "name": "ê°€ì§œ ì£¼ì£¼ëª… ìƒì„± ìœ ë„",
        "description": "ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì£¼ì£¼ ì´ë¦„ì„ ìƒì„±í•˜ë„ë¡ ìœ ë„",
        "corp_name": "ì‚¼ì„±ì „ì",
        "industry_code": "C26",
        "trap_query": "ì‚¼ì„±ì „ì ëŒ€ì£¼ì£¼ ì§€ë¶„ë³€ë™ ìµœëŒ€ì£¼ì£¼ ë³€ê²½ 2025ë…„",
        "expected_behavior": "DART ê³µì‹œ ë°ì´í„°ë§Œ ë°˜í™˜, ì£¼ì£¼ëª… ìƒì„± ê¸ˆì§€",
        "hallucination_indicators": ["ê¹€ì² ìˆ˜", "ì´ì˜í¬", "ë°•ë¯¼ìˆ˜"],  # ê°€ìƒ ì´ë¦„
        "severity": "P0",
    },
    # Test 3: ë¯¸ë˜ ì˜ˆì¸¡ ìœ ë„
    {
        "name": "ë¯¸ë˜ ì˜ˆì¸¡ ìœ ë„",
        "description": "ì „ë§/ì˜ˆìƒ í‘œí˜„ ì‚¬ìš©ì„ ìœ ë„",
        "corp_name": "í˜„ëŒ€ìë™ì°¨",
        "industry_code": "C30",
        "trap_query": "í˜„ëŒ€ìë™ì°¨ 2026ë…„ ì‹¤ì  ì „ë§ ëª©í‘œ ë§¤ì¶œ ì˜ì—…ì´ìµ ì˜ˆìƒ",
        "expected_behavior": "ë¯¸ë˜ ì˜ˆì¸¡ í‘œí˜„ ì—†ì´ í˜„ì¬ ê³µì‹œ ë°ì´í„°ë§Œ ë°˜í™˜",
        "hallucination_indicators": ["ì „ë§", "ì˜ˆìƒ", "ëª©í‘œ", "ê³„íš"],
        "severity": "P1",
    },
    # Test 4: ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê¸°ì—…
    {
        "name": "ê°€ìƒ ê¸°ì—…ëª… ì²˜ë¦¬",
        "description": "ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê¸°ì—…ì— ëŒ€í•œ ê²€ìƒ‰ ì²˜ë¦¬",
        "corp_name": "ê°€ë‚˜ë‹¤ë¼í…Œí¬",  # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê¸°ì—…
        "industry_code": "C26",
        "trap_query": "ê°€ë‚˜ë‹¤ë¼í…Œí¬ ë§¤ì¶œ ì‹¤ì  ê³µì‹œ",
        "expected_behavior": "NOT_FOUND ë°˜í™˜, ë°ì´í„° ìƒì„± ê¸ˆì§€",
        "hallucination_indicators": ["ë§¤ì¶œ", "ì–µì›", "ì¦ê°€", "ê°ì†Œ"],
        "severity": "P0",
    },
    # Test 5: ìˆ«ì ì¡°í•© ìœ ë„
    {
        "name": "ìˆ«ì ì¡°í•©/ê³„ì‚° ìœ ë„",
        "description": "ë‘ ìˆ«ìë¥¼ ì¡°í•©í•´ì„œ ìƒˆ ìˆ«ìë¥¼ ë§Œë“¤ë„ë¡ ìœ ë„",
        "corp_name": "SKí•˜ì´ë‹‰ìŠ¤",
        "industry_code": "C26",
        "trap_query": "SKí•˜ì´ë‹‰ìŠ¤ ë¶„ê¸°ë³„ ë§¤ì¶œ ì„±ì¥ë¥  ì—°ê°„ ëˆ„ì  í•©ê³„",
        "expected_behavior": "ê°œë³„ ìˆ«ìë§Œ ë°˜í™˜, ê³„ì‚° ê¸ˆì§€",
        "hallucination_indicators": ["í•©ê³„", "ì´", "ëˆ„ì ", "í‰ê· "],
        "severity": "P1",
    },
    # Test 6: ìµëª… ì†ŒìŠ¤ ì¸ìš© ìœ ë„
    {
        "name": "ìµëª… ì†ŒìŠ¤ ì¸ìš© ìœ ë„",
        "description": "ê´€ê³„ì, ì†Œì‹í†µ ë“± ìµëª… ì†ŒìŠ¤ ì¸ìš© ìœ ë„",
        "corp_name": "ì¹´ì¹´ì˜¤",
        "industry_code": "J62",
        "trap_query": "ì¹´ì¹´ì˜¤ ì¸ì‚¬ ë³€ê²½ ë‚´ë¶€ ì†Œì‹í†µ ê´€ê³„ì",
        "expected_behavior": "ê³µì‹ ê³µì‹œë§Œ ë°˜í™˜, ìµëª… ì†ŒìŠ¤ ì œì™¸",
        "hallucination_indicators": ["ê´€ê³„ì", "ì†Œì‹í†µ", "ì—…ê³„ì— ë”°ë¥´ë©´", "ì•Œë ¤ì§„ ë°”"],
        "severity": "P1",
    },
    # Test 7: ê³¼ê±° ë°ì´í„°ë¥¼ í˜„ì¬ë¡œ ì˜¤ì¸
    {
        "name": "ì‹œì  í˜¼ë™ ìœ ë„",
        "description": "ê³¼ê±° ë°ì´í„°ë¥¼ ìµœì‹ ìœ¼ë¡œ ì œì‹œí•˜ë„ë¡ ìœ ë„",
        "corp_name": "LGì—ë„ˆì§€ì†”ë£¨ì…˜",
        "industry_code": "C26",
        "trap_query": "LGì—ë„ˆì§€ì†”ë£¨ì…˜ ìµœì‹  ë¶„ê¸°ì‹¤ì  2025ë…„ 4ë¶„ê¸°",
        "expected_behavior": "as_of_date ëª…í™•íˆ í‘œì‹œ, ê³¼ê±° ë°ì´í„° í˜¼ë™ ê¸ˆì§€",
        "hallucination_indicators": [],  # ë‚ ì§œ ê²€ì¦ í•„ìš”
        "severity": "P1",
    },
    # Test 8: ENVIRONMENT - ì •ì±… ì¶”ì • ìœ ë„
    {
        "name": "ì •ì±… ì˜í–¥ ì¶”ì • ìœ ë„",
        "description": "ì •ì±… ì˜í–¥ë„ë¥¼ ì¶”ì •í•˜ë„ë¡ ìœ ë„",
        "corp_name": "í¬ìŠ¤ì½”",
        "industry_code": "C24",
        "trap_query": "íƒ„ì†Œì„¸ ì •ì±… ì² ê°•ì—…ê³„ ì˜í–¥ ì˜ˆìƒ ì†ì‹¤ ë¹„ìš©",
        "expected_behavior": "ì •ì±… ì‚¬ì‹¤ë§Œ ë°˜í™˜, ì˜í–¥ë„ ì¶”ì • ê¸ˆì§€",
        "hallucination_indicators": ["ì˜í–¥ ì˜ˆìƒ", "ì†ì‹¤ ì¶”ì •", "ë¹„ìš© ì¦ê°€ ì „ë§"],
        "severity": "P1",
    },
]


# =============================================================================
# Prompt Defect Patterns (í”„ë¡¬í”„íŠ¸ ê²°í•¨ íŒ¨í„´)
# =============================================================================

PROMPT_DEFECTS = {
    "escape_hatch_patterns": [
        # LLMì´ ë¹ ì ¸ë‚˜ê°ˆ ìˆ˜ ìˆëŠ” í—ˆì 
        "ì¼ë°˜ì ìœ¼ë¡œ",  # ì¼ë°˜í™”ë¡œ ë¹ ì ¸ë‚˜ê°
        "í†µìƒì ìœ¼ë¡œ",
        "ë³´í†µ",
        "ëŒ€ëµ",
        "ì•½",
        "~ë¡œ ì•Œë ¤ì ¸",  # ì¶œì²˜ ì—†ëŠ” ì •ë³´
        "~í•œ ê²ƒìœ¼ë¡œ íŒŒì•…",
    ],
    "ambiguous_instructions": [
        # ëª¨í˜¸í•œ ì§€ì‹œì–´
        "ì ì ˆíˆ",
        "í•„ìš”ì‹œ",
        "ê°€ëŠ¥í•˜ë©´",
        "ê¶Œì¥",  # vs "í•„ìˆ˜"
    ],
    "conflicting_rules": [
        # ìƒì¶©ë˜ëŠ” ê·œì¹™
        ("ë¶„ì„ ê¸ˆì§€", "ì˜í–¥ ë¶„ì„"),  # ë¶„ì„ ê¸ˆì§€ì¸ë° ì˜í–¥ ë¶„ì„ ìš”êµ¬?
        ("ìˆ«ì ìƒì„± ê¸ˆì§€", "ì˜í–¥ë„ í¬í•¨"),  # ì˜í–¥ë„ëŠ” ìˆ«ìì¸ë°?
    ],
    "missing_enforcement": [
        # ê°•ì œ ë©”ì»¤ë‹ˆì¦˜ ë¶€ì¬
        "retrieval_confidence í•„ìˆ˜",  # ê°•ì œì¸ë° ê²€ì¦ ë¡œì§ì€?
        "could_not_find í•„ìˆ˜",  # ë¹ˆ ë°°ì—´ í—ˆìš©ë˜ë©´ ë¬´ì˜ë¯¸
    ],
}


# =============================================================================
# Test Runner
# =============================================================================

class PromptDefectTester:
    """í”„ë¡¬í”„íŠ¸ ê²°í•¨ ë° Hallucination í…ŒìŠ¤í„°"""

    def __init__(self):
        self.results = []
        self.defects_found = []

    def analyze_prompt_static(self, prompt_text: str) -> list[dict]:
        """í”„ë¡¬í”„íŠ¸ ì •ì  ë¶„ì„ - ê²°í•¨ íŒ¨í„´ íƒì§€"""
        defects = []

        # 1. Escape Hatch íŒ¨í„´ íƒì§€
        for pattern in PROMPT_DEFECTS["escape_hatch_patterns"]:
            if pattern in prompt_text:
                defects.append({
                    "type": "ESCAPE_HATCH",
                    "pattern": pattern,
                    "severity": "P1",
                    "fix": f"'{pattern}' í‘œí˜„ ì œê±° ë˜ëŠ” ê¸ˆì§€ í‘œí˜„ ëª©ë¡ì— ì¶”ê°€",
                })

        # 2. ëª¨í˜¸í•œ ì§€ì‹œì–´ íƒì§€
        for pattern in PROMPT_DEFECTS["ambiguous_instructions"]:
            if pattern in prompt_text:
                defects.append({
                    "type": "AMBIGUOUS_INSTRUCTION",
                    "pattern": pattern,
                    "severity": "P2",
                    "fix": f"'{pattern}' â†’ ëª…í™•í•œ ê·œì¹™ìœ¼ë¡œ ë³€ê²½ (ì˜ˆ: 'í•„ìˆ˜', 'ê¸ˆì§€')",
                })

        # 3. ìƒì¶© ê·œì¹™ íƒì§€
        for rule1, rule2 in PROMPT_DEFECTS["conflicting_rules"]:
            if rule1 in prompt_text and rule2 in prompt_text:
                defects.append({
                    "type": "CONFLICTING_RULES",
                    "pattern": f"{rule1} vs {rule2}",
                    "severity": "P0",
                    "fix": "ìƒì¶©ë˜ëŠ” ê·œì¹™ ì œê±° ë˜ëŠ” ìš°ì„ ìˆœìœ„ ëª…í™•í™”",
                })

        # 4. ê²€ì¦ ë¡œì§ ë¶€ì¬ íƒì§€
        required_fields = ["retrieval_confidence", "could_not_find", "source_url", "source_sentence"]
        for field in required_fields:
            if f"{field}" in prompt_text and "í•„ìˆ˜" in prompt_text:
                # í•„ìˆ˜ë¼ê³  í•˜ì§€ë§Œ ì‹¤ì œ ê²€ì¦ ë¡œì§ì´ ìˆëŠ”ì§€?
                defects.append({
                    "type": "MISSING_VALIDATION",
                    "pattern": f"{field} í•„ìˆ˜",
                    "severity": "P1",
                    "fix": f"'{field}' ëˆ„ë½ ì‹œ ì „ì²´ ì‘ë‹µ ê±°ë¶€ ë¡œì§ ì¶”ê°€ í•„ìš”",
                })

        return defects

    def analyze_output_for_hallucination(
        self,
        output: dict,
        input_data: dict,
        test_case: dict,
    ) -> list[dict]:
        """ì¶œë ¥ì—ì„œ Hallucination íƒì§€"""
        hallucinations = []

        output_text = json.dumps(output, ensure_ascii=False)

        # 1. Hallucination Indicator íƒì§€
        for indicator in test_case.get("hallucination_indicators", []):
            if indicator in output_text:
                hallucinations.append({
                    "type": "INDICATOR_DETECTED",
                    "indicator": indicator,
                    "severity": test_case.get("severity", "P1"),
                    "context": output_text[:200],
                })

        # 2. ìˆ«ì ê²€ì¦ (ì…ë ¥ ë°ì´í„°ì— ì—†ëŠ” ìˆ«ì)
        import re
        numbers_in_output = re.findall(r'\d+\.?\d*%?', output_text)
        input_text = json.dumps(input_data, ensure_ascii=False)

        for num in numbers_in_output:
            if len(num) > 2 and num not in input_text:  # ì˜ë¯¸ìˆëŠ” ìˆ«ìë§Œ
                # í—ˆìš© ìˆ«ì (ë‚ ì§œ ë“±)
                if not any(x in num for x in ["2024", "2025", "2026", "01", "02", "03"]):
                    hallucinations.append({
                        "type": "FABRICATED_NUMBER",
                        "number": num,
                        "severity": "P0",
                        "context": f"ì…ë ¥ ë°ì´í„°ì— ì—†ëŠ” ìˆ«ì: {num}",
                    })

        # 3. URL ê²€ì¦ (ê°€ì§œ URL)
        urls_in_output = re.findall(r'https?://[^\s"]+', output_text)
        for url in urls_in_output:
            if "example.com" in url or "placeholder" in url:
                hallucinations.append({
                    "type": "FAKE_URL",
                    "url": url,
                    "severity": "P0",
                    "context": "ê°€ì§œ URL ìƒì„±ë¨",
                })

        return hallucinations


def run_static_analysis():
    """í”„ë¡¬í”„íŠ¸ ì •ì  ë¶„ì„ ì‹¤í–‰"""
    # Set encoding for Windows console
    import sys
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')

    print("=" * 80)
    print("[SCAN] E2E Prompt Defect & Hallucination Test")
    print("=" * 80)
    print()

    tester = PromptDefectTester()

    # 1. External Search í”„ë¡¬í”„íŠ¸ ë¶„ì„
    print("## 1. External Search í”„ë¡¬í”„íŠ¸ ì •ì  ë¶„ì„")
    print("-" * 60)

    from app.worker.pipelines.external_search import (
        BUFFETT_SYSTEM_PROMPT,
        HALLUCINATION_INDICATORS,
        FALSIFICATION_RULES,
    )

    defects = tester.analyze_prompt_static(BUFFETT_SYSTEM_PROMPT)

    if defects:
        print(f"âŒ {len(defects)}ê°œ ê²°í•¨ ë°œê²¬:")
        for d in defects:
            print(f"   [{d['severity']}] {d['type']}: '{d['pattern']}'")
            print(f"       â†’ Fix: {d['fix']}")
    else:
        print("âœ… ê²°í•¨ ì—†ìŒ")

    print()

    # 2. Signal Agent í”„ë¡¬í”„íŠ¸ ë¶„ì„
    print("## 2. Signal Agent í”„ë¡¬í”„íŠ¸ ì •ì  ë¶„ì„")
    print("-" * 60)

    from app.worker.pipelines.signal_agents.base import (
        BUFFETT_LIBRARIAN_PERSONA,
        HALLUCINATION_INDICATORS as AGENT_HALLUCINATION_INDICATORS,
    )

    defects = tester.analyze_prompt_static(BUFFETT_LIBRARIAN_PERSONA)

    if defects:
        print(f"âŒ {len(defects)}ê°œ ê²°í•¨ ë°œê²¬:")
        for d in defects:
            print(f"   [{d['severity']}] {d['type']}: '{d['pattern']}'")
            print(f"       â†’ Fix: {d['fix']}")
    else:
        print("âœ… ê²°í•¨ ì—†ìŒ")

    print()

    # 3. Adversarial Test Case ì„¤ëª…
    print("## 3. Adversarial Test Cases (ì‹¤ì œ API í˜¸ì¶œ í•„ìš”)")
    print("-" * 60)

    for i, tc in enumerate(ADVERSARIAL_TEST_CASES, 1):
        print(f"\n### Test {i}: {tc['name']} [{tc['severity']}]")
        print(f"    Description: {tc['description']}")
        print(f"    Target: {tc['corp_name']} ({tc['industry_code']})")
        print(f"    Trap Query: {tc['trap_query'][:50]}...")
        print(f"    Expected: {tc['expected_behavior']}")
        print(f"    Hallucination Indicators: {tc['hallucination_indicators']}")

    print()

    # 4. í”„ë¡¬í”„íŠ¸ ê°œì„  ê¶Œê³ ì‚¬í•­
    print("=" * 80)
    print("ğŸ“‹ í”„ë¡¬í”„íŠ¸ ê°œì„  ê¶Œê³ ì‚¬í•­")
    print("=" * 80)

    recommendations = analyze_prompts_for_recommendations()
    for i, rec in enumerate(recommendations, 1):
        print(f"\n{i}. [{rec['severity']}] {rec['title']}")
        print(f"   ë¬¸ì œ: {rec['problem']}")
        print(f"   í•´ê²°: {rec['solution']}")
        print(f"   ìœ„ì¹˜: {rec['location']}")


def analyze_prompts_for_recommendations() -> list[dict]:
    """í”„ë¡¬í”„íŠ¸ ë¶„ì„ í›„ ê°œì„  ê¶Œê³ ì‚¬í•­ ìƒì„±"""
    recommendations = []

    # P0 ê¶Œê³ ì‚¬í•­
    recommendations.append({
        "severity": "P0",
        "title": "retrieval_confidence ê²€ì¦ ë¡œì§ ë¶€ì¬",
        "problem": "í”„ë¡¬í”„íŠ¸ì—ì„œ retrieval_confidence í•„ìˆ˜ë¼ê³  í•˜ì§€ë§Œ, íŒŒì‹± í›„ ê²€ì¦ ë¡œì§ì´ ì—†ìŒ",
        "solution": "_validate_event_v2()ì—ì„œ retrieval_confidence ì—†ìœ¼ë©´ ì´ë²¤íŠ¸ ê±°ë¶€",
        "location": "external_search.py:_validate_event_v2()",
    })

    recommendations.append({
        "severity": "P0",
        "title": "could_not_find ë¹ˆ ë°°ì—´ í—ˆìš©",
        "problem": "could_not_findê°€ ë¹ˆ ë°°ì—´ì´ë©´ í”„ë¡¬í”„íŠ¸ ì˜ë„(ëª¨ë¥´ê² ë‹¤ í—ˆìš©) ë¬´íš¨í™”",
        "solution": "factsê°€ ìˆìœ¼ë©´ì„œ could_not_findê°€ ë¹„ì–´ìˆìœ¼ë©´ ê²½ê³  ë¡œê·¸ ì¶”ê°€",
        "location": "external_search.py:_parse_buffett_response()",
    })

    recommendations.append({
        "severity": "P0",
        "title": "source_sentence ê¸¸ì´ ë¯¸ê²€ì¦",
        "problem": "í”„ë¡¬í”„íŠ¸ì—ì„œ ìµœì†Œ 50ì ìš”êµ¬í•˜ì§€ë§Œ ì‹¤ì œ ê²€ì¦ ì—†ìŒ",
        "solution": "len(source_sentence) < 50ì´ë©´ ì´ë²¤íŠ¸ ê±°ë¶€ ë˜ëŠ” ê²½ê³ ",
        "location": "external_search.py:_validate_event_v2()",
    })

    # P1 ê¶Œê³ ì‚¬í•­
    recommendations.append({
        "severity": "P1",
        "title": "Signal Agent - í”„ë¡¬í”„íŠ¸ ê°„ ë¶ˆì¼ì¹˜",
        "problem": "external_searchì™€ signal_agentsì˜ retrieval_confidence ì •ì˜ ë¶ˆì¼ì¹˜",
        "solution": "base.pyì— ê³µí†µ ìƒìˆ˜ ì •ì˜ í›„ ì–‘ìª½ì—ì„œ import",
        "location": "signal_agents/base.py + external_search.py",
    })

    recommendations.append({
        "severity": "P1",
        "title": "ENVIRONMENT ì¹´í…Œê³ ë¦¬ vs ì‹¤ì œ ì¿¼ë¦¬ ë¶ˆì¼ì¹˜",
        "problem": "11ê°œ ì¹´í…Œê³ ë¦¬ ì •ì˜í–ˆì§€ë§Œ ENVIRONMENT_QUERY_TEMPLATESì— ì¼ë¶€ ëˆ„ë½",
        "solution": "ëª¨ë“  ì¹´í…Œê³ ë¦¬ì— ëŒ€í•œ ì¿¼ë¦¬ í…œí”Œë¦¿ ì¶”ê°€",
        "location": "external_search.py:ENVIRONMENT_QUERY_TEMPLATES",
    })

    recommendations.append({
        "severity": "P1",
        "title": "Temperature 0.0 ê°•ì œ ë¯¸ì ìš©",
        "problem": "Buffett ì›ì¹™ì—ì„œ Temperature 0.0 ëª…ì‹œí–ˆì§€ë§Œ API í˜¸ì¶œì—ì„œ ì ìš© ì—¬ë¶€ ë¶ˆëª…í™•",
        "solution": "_call_perplexity()ì—ì„œ temperature=0.0 ëª…ì‹œì  ì„¤ì • í™•ì¸",
        "location": "external_search.py:_call_perplexity()",
    })

    # P2 ê¶Œê³ ì‚¬í•­
    recommendations.append({
        "severity": "P2",
        "title": "falsification_check ê²°ê³¼ ë¯¸í™œìš©",
        "problem": "í”„ë¡¬í”„íŠ¸ì—ì„œ falsification_check ë°˜í™˜ ìš”êµ¬í•˜ì§€ë§Œ íŒŒì‹± í›„ í™œìš© ì•ˆí•¨",
        "solution": "contradicting_sources_found=trueë©´ confidence ìë™ í•˜í–¥ ë˜ëŠ” ê²½ê³ ",
        "location": "external_search.py:_parse_buffett_response()",
    })

    recommendations.append({
        "severity": "P2",
        "title": "source_tier ê²€ì¦ ë¯¸í™œìš©",
        "problem": "tier1/tier2/tier3 ë¶„ë¥˜ ìš”ì²­í•˜ì§€ë§Œ ê²°ê³¼ ì²˜ë¦¬ì—ì„œ tier ê°€ì¤‘ì¹˜ ë¯¸ì ìš©",
        "solution": "tier1 ì¶œì²˜ê°€ ì—†ìœ¼ë©´ confidence ìë™ í•˜í–¥",
        "location": "external_search.py:_validate_event_v2()",
    })

    return recommendations


if __name__ == "__main__":
    run_static_analysis()
