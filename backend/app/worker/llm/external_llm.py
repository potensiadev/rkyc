"""
External LLM Service
ë³´ì•ˆ ì•„í‚¤í…ì²˜: ì™¸ë¶€ ê³µê°œ ë°ì´í„° ì „ìš© LLM

âœ… í—ˆìš© ì‘ì—…:
- ê³µê°œ ë‰´ìŠ¤/ê¸°ì‚¬ ìˆ˜ì§‘ ë° ìš”ì•½
- DART ê³µì‹œ ì •ë³´ ë¶„ì„
- ì •ì±…/ê·œì œ ë³€í™” ëª¨ë‹ˆí„°ë§
- ì‚°ì—… ë™í–¥ ë¶„ì„
- ì™¸ë¶€ ì´ë²¤íŠ¸ â†’ ì‹œê·¸ë„ ì´ˆì•ˆ ìƒì„±

âŒ ê¸ˆì§€ ì‘ì—…:
- íŠ¹ì • ë²•ì¸ ê³ ê° ì •ë³´ ì²˜ë¦¬
- ë‚´ë¶€ ì—¬ì‹ /ë‹´ë³´ ì •ë³´ ë¶„ì„
- ê³ ê° ê±°ë˜ ë‚´ì—­ ì²˜ë¦¬
- ë‚´ë¶€ ì‹ ìš©ë“±ê¸‰ ê´€ë ¨ ë¶„ì„
"""

import json
import hashlib
import logging
from datetime import datetime
from typing import Optional

import httpx
import litellm
from litellm import completion

from app.core.config import settings
from app.worker.llm.exceptions import (
    AllProvidersFailedError,
    InvalidResponseError,
)
from app.worker.llm.key_rotator import get_key_rotator

logger = logging.getLogger(__name__)


class ExternalLLMService:
    """
    External LLM Service - ê³µê°œ ë°ì´í„° ì „ìš©

    ì—­í• :
    - ë‰´ìŠ¤/ê³µì‹œ/ì •ì±… ë¶„ì„ ë° ìš”ì•½
    - ì—…ì¢…ë³„ ì¸í…”ë¦¬ì „ìŠ¤ ì§‘ê³„
    - ì‹œê·¸ë„ í›„ë³´ ì‹ë³„

    ğŸ”“ ê³µê°œ ë°ì´í„°ë§Œ ì²˜ë¦¬:
    - ë‰´ìŠ¤, DART ê³µì‹œ, ì •ì±…/ê·œì œ, ì‚°ì—… ë¦¬í¬íŠ¸
    """

    # External LLM ëª¨ë¸ ì„¤ì •
    ANALYSIS_MODELS = [
        {"model": "claude-3-5-sonnet-20240620", "provider": "anthropic"},
        {"model": "gpt-4o", "provider": "openai"},
    ]

    PERPLEXITY_API_URL = "https://api.perplexity.ai/chat/completions"
    PERPLEXITY_MODEL = "sonar-pro"

    MAX_RETRIES = 3
    INITIAL_DELAY = 1.0
    TIMEOUT = 30.0

    def __init__(self):
        self._configure_api_keys()
        # Use Key Rotator for Perplexity API key (supports _1, _2, _3 rotation)
        self.key_rotator = get_key_rotator()
        self.perplexity_api_key = self.key_rotator.get_key("perplexity")
        self.perplexity_enabled = bool(self.perplexity_api_key)

    def _configure_api_keys(self):
        """API í‚¤ ì„¤ì •"""
        # External LLMìš© ë³„ë„ í‚¤ ìš°ì„  ì‚¬ìš©
        import os
        external_anthropic = os.getenv("EXTERNAL_LLM_ANTHROPIC_KEY", settings.ANTHROPIC_API_KEY)
        external_openai = os.getenv("EXTERNAL_LLM_OPENAI_KEY", settings.OPENAI_API_KEY)

        if external_anthropic:
            litellm.anthropic_key = external_anthropic
        if external_openai:
            litellm.openai_key = external_openai

    # =========================================
    # ë‰´ìŠ¤/ì´ë²¤íŠ¸ ìˆ˜ì§‘ ë° ë¶„ì„
    # =========================================

    def search_external_news(
        self,
        query: str,
        industry_name: str = "",
        days: int = 30,
    ) -> list[dict]:
        """
        Perplexity APIë¡œ ì™¸ë¶€ ë‰´ìŠ¤ ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬ (ê¸°ì—…ëª…, í‚¤ì›Œë“œ ë“±)
            industry_name: ì—…ì¢…ëª… (ì»¨í…ìŠ¤íŠ¸ìš©)
            days: ê²€ìƒ‰ ê¸°ê°„ (ì¼)

        Returns:
            list[dict]: ê²€ìƒ‰ëœ ë‰´ìŠ¤/ì´ë²¤íŠ¸ ëª©ë¡
        """
        if not self.perplexity_enabled:
            logger.warning("Perplexity API not configured - search disabled")
            return []

        try:
            prompt = self._build_search_prompt(query, industry_name, days)

            headers = {
                "Authorization": f"Bearer {self.perplexity_api_key}",
                "Content-Type": "application/json",
            }

            payload = {
                "model": self.PERPLEXITY_MODEL,
                "messages": [
                    {
                        "role": "system",
                        "content": (
                            "You are a financial analyst searching for external news "
                            "and events. Focus on publicly available information only. "
                            "Return results in JSON format."
                        ),
                    },
                    {"role": "user", "content": prompt},
                ],
                "temperature": 0.1,
                "max_tokens": 2000,
            }

            with httpx.Client(timeout=self.TIMEOUT) as client:
                response = client.post(
                    self.PERPLEXITY_API_URL,
                    headers=headers,
                    json=payload,
                )
                response.raise_for_status()

            result = response.json()
            content = result.get("choices", [{}])[0].get("message", {}).get("content", "")

            events = self._parse_news_events(content)
            logger.info(f"[External LLM] Found {len(events)} news events for query: {query}")

            return events

        except Exception as e:
            logger.error(f"[External LLM] News search failed: {e}")
            return []

    def analyze_news_article(
        self,
        title: str,
        content: str,
        source_url: str,
    ) -> dict:
        """
        ê°œë³„ ë‰´ìŠ¤ ê¸°ì‚¬ ë¶„ì„

        Args:
            title: ê¸°ì‚¬ ì œëª©
            content: ê¸°ì‚¬ ë³¸ë¬¸
            source_url: ì¶œì²˜ URL

        Returns:
            dict: ë¶„ì„ ê²°ê³¼ (ìš”ì•½, ì—…ì¢…ì½”ë“œ, í‚¤ì›Œë“œ, ì„¼í‹°ë¨¼íŠ¸ ë“±)
        """
        system_prompt = """You are a financial news analyst. Analyze the given news article and extract:
1. Brief summary in Korean (200 chars max)
2. Related industry codes (Korean standard industry classification)
3. Key entities (company names, people)
4. Keywords
5. Event category (INDUSTRY_SHOCK, POLICY_CHANGE, MARKET_TREND, COMPANY_NEWS, etc.)
6. Sentiment (POSITIVE, NEGATIVE, NEUTRAL)
7. Impact level (HIGH, MED, LOW)
8. Whether this could generate a risk signal (is_signal_candidate)

Return JSON:
{
    "summary_ko": "...",
    "industry_codes": ["C26", "C29"],
    "entities": {"companies": [], "people": []},
    "keywords": [],
    "event_category": "...",
    "sentiment": "...",
    "impact_level": "...",
    "is_signal_candidate": true/false,
    "signal_type_hint": "INDUSTRY" or "ENVIRONMENT" (if is_signal_candidate)
}"""

        user_prompt = f"""Analyze this news article:

Title: {title}
Source: {source_url}

Content:
{content[:3000]}

Extract the required information."""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]

        try:
            result = self._call_with_fallback(
                messages=messages,
                response_format={"type": "json_object"},
            )
            return json.loads(result)
        except (json.JSONDecodeError, AllProvidersFailedError) as e:
            logger.error(f"[External LLM] News analysis failed: {e}")
            return {
                "summary_ko": title[:200],
                "industry_codes": [],
                "entities": {},
                "keywords": [],
                "event_category": "UNKNOWN",
                "sentiment": "NEUTRAL",
                "impact_level": "LOW",
                "is_signal_candidate": False,
            }

    # =========================================
    # ì—…ì¢…ë³„ ì¸í…”ë¦¬ì „ìŠ¤ ì§‘ê³„
    # =========================================

    def aggregate_industry_intel(
        self,
        industry_code: str,
        news_summaries: list[dict],
        period_start: str,
        period_end: str,
    ) -> dict:
        """
        ì—…ì¢…ë³„ ì¸í…”ë¦¬ì „ìŠ¤ ì§‘ê³„ ë° ìš”ì•½

        Args:
            industry_code: ì—…ì¢… ì½”ë“œ (ì˜ˆ: C26)
            news_summaries: í•´ë‹¹ ê¸°ê°„ ë‰´ìŠ¤ ìš”ì•½ ëª©ë¡
            period_start: ì§‘ê³„ ì‹œì‘ì¼ (YYYY-MM-DD)
            period_end: ì§‘ê³„ ì¢…ë£Œì¼ (YYYY-MM-DD)

        Returns:
            dict: ì§‘ê³„ëœ ì¸í…”ë¦¬ì „ìŠ¤
        """
        if not news_summaries:
            return {
                "period_summary": f"{industry_code} ì—…ì¢…ì— ëŒ€í•œ ì£¼ìš” ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.",
                "key_events": [],
                "risk_factors": [],
                "opportunity_factors": [],
            }

        # ë‰´ìŠ¤ ìš”ì•½ í…ìŠ¤íŠ¸ êµ¬ì„±
        news_text = "\n".join([
            f"- [{n.get('sentiment', 'N/A')}] {n.get('summary_ko', '')}"
            for n in news_summaries[:20]  # ìµœëŒ€ 20ê°œ
        ])

        system_prompt = """You are an industry analyst. Aggregate news summaries and generate:
1. Period summary (Korean, 2-3 sentences)
2. Key events list
3. Identified risk factors
4. Identified opportunity factors

Return JSON:
{
    "period_summary": "ì´ë²ˆ ì£¼ í•´ë‹¹ ì—…ì¢…ì€...",
    "key_events": [{"event": "...", "impact": "HIGH/MED/LOW"}],
    "risk_factors": [{"factor": "...", "severity": "HIGH/MED/LOW"}],
    "opportunity_factors": [{"factor": "...", "potential": "HIGH/MED/LOW"}]
}"""

        user_prompt = f"""Aggregate news for industry {industry_code}
Period: {period_start} ~ {period_end}

News summaries:
{news_text}

Generate an intelligence summary."""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]

        try:
            result = self._call_with_fallback(
                messages=messages,
                response_format={"type": "json_object"},
            )
            return json.loads(result)
        except Exception as e:
            logger.error(f"[External LLM] Industry intel aggregation failed: {e}")
            return {
                "period_summary": f"{industry_code} ì—…ì¢… ë¶„ì„ ì‹¤íŒ¨",
                "key_events": [],
                "risk_factors": [],
                "opportunity_factors": [],
            }

    # =========================================
    # ì •ì±…/ê·œì œ ë¶„ì„
    # =========================================

    def analyze_policy(
        self,
        policy_title: str,
        policy_content: str,
        issuing_body: str,
    ) -> dict:
        """
        ì •ì±…/ê·œì œ ë¬¸ì„œ ë¶„ì„

        Args:
            policy_title: ì •ì±…ëª…
            policy_content: ì •ì±… ë‚´ìš©
            issuing_body: ë°œí–‰ ê¸°ê´€ (ê¸ˆìœµìœ„, ê¸ˆê°ì› ë“±)

        Returns:
            dict: ë¶„ì„ ê²°ê³¼ (ìš”ì•½, ì˜í–¥ ì—…ì¢…, í•„ìš” ì¡°ì¹˜ ë“±)
        """
        system_prompt = """You are a regulatory analyst. Analyze the policy/regulation and extract:
1. Summary in Korean
2. Affected industries (codes)
3. Impact analysis
4. Required actions

Return JSON:
{
    "summary": "...",
    "affected_industries": ["C26", "K64"],
    "impact_analysis": "...",
    "action_required": "...",
    "effective_date": "YYYY-MM-DD or null"
}"""

        user_prompt = f"""Analyze this policy/regulation:

Title: {policy_title}
Issuing Body: {issuing_body}

Content:
{policy_content[:4000]}

Identify affected industries and required actions."""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]

        try:
            result = self._call_with_fallback(
                messages=messages,
                response_format={"type": "json_object"},
            )
            return json.loads(result)
        except Exception as e:
            logger.error(f"[External LLM] Policy analysis failed: {e}")
            return {
                "summary": policy_title,
                "affected_industries": [],
                "impact_analysis": "",
                "action_required": "",
                "effective_date": None,
            }

    # =========================================
    # í—¬í¼ ë©”ì„œë“œ
    # =========================================

    def _call_with_fallback(
        self,
        messages: list[dict],
        response_format: Optional[dict] = None,
        temperature: float = 0.1,
        max_tokens: int = 2048,
    ) -> str:
        """Fallback ì²´ì¸ì„ ì‚¬ìš©í•œ LLM í˜¸ì¶œ"""
        errors = []

        for model_config in self.ANALYSIS_MODELS:
            model = model_config["model"]

            try:
                logger.info(f"[External LLM] Calling {model}")

                kwargs = {
                    "model": model,
                    "messages": messages,
                    "temperature": temperature,
                    "max_tokens": max_tokens,
                }

                if response_format:
                    kwargs["response_format"] = response_format

                response = completion(**kwargs)
                content = response.choices[0].message.content

                logger.info(f"[External LLM] Success from {model}")
                return content

            except Exception as e:
                errors.append({"model": model, "error": str(e)})
                logger.warning(f"[External LLM] {model} failed: {e}")

        raise AllProvidersFailedError(
            message="[External LLM] All providers failed",
            errors=errors,
        )

    def _build_search_prompt(self, query: str, industry_name: str, days: int) -> str:
        """ê²€ìƒ‰ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        today = datetime.now().strftime("%Y-%m-%d")

        return f"""Search for recent news and events (last {days} days) related to:

Query: {query}
Industry: {industry_name}

Find information about:
1. Regulatory or legal issues
2. Industry-wide events or shocks
3. Financial news (earnings, debt)
4. Leadership or ownership changes
5. Policy or regulation changes

Today's date: {today}

Return JSON array:
[
  {{
    "title": "...",
    "summary": "Brief summary",
    "source_url": "URL",
    "published_at": "YYYY-MM-DD",
    "relevance": "HIGH/MED/LOW"
  }}
]

If no relevant events, return: []"""

    def _parse_news_events(self, content: str) -> list[dict]:
        """Perplexity ì‘ë‹µì—ì„œ ë‰´ìŠ¤ ì´ë²¤íŠ¸ íŒŒì‹±"""
        try:
            start_idx = content.find("[")
            end_idx = content.rfind("]") + 1

            if start_idx == -1 or end_idx == 0:
                return []

            json_str = content[start_idx:end_idx]
            events = json.loads(json_str)

            # í•„ìˆ˜ í•„ë“œ ê²€ì¦
            valid_events = []
            for event in events:
                if event.get("title") and event.get("summary"):
                    # URL í•´ì‹œ ìƒì„±
                    url = event.get("source_url", "")
                    if url:
                        event["url_hash"] = hashlib.sha256(url.encode()).hexdigest()
                    valid_events.append(event)

            return valid_events

        except json.JSONDecodeError:
            return []

    @staticmethod
    def generate_url_hash(url: str) -> str:
        """URLì˜ SHA256 í•´ì‹œ ìƒì„±"""
        return hashlib.sha256(url.encode()).hexdigest()


def get_external_llm() -> ExternalLLMService:
    """External LLM ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return ExternalLLMService()
