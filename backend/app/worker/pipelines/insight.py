"""
Insight Pipeline Stage
Stage 8: Generate final briefing using LLM with similar case search
"""

import logging
from typing import Optional

from sqlalchemy import text

from app.worker.db import get_sync_db
from app.worker.llm.service import LLMService
from app.worker.llm.prompts import INSIGHT_GENERATION_PROMPT
from app.worker.llm.exceptions import AllProvidersFailedError
from app.worker.llm.embedding import get_embedding_service, EmbeddingError

logger = logging.getLogger(__name__)


class InsightPipeline:
    """
    Stage 8: INSIGHT - Generate final briefing summary with similar case search

    Uses LLM to generate a concise executive briefing
    summarizing all detected signals and their implications.

    Enhanced with:
    - Similar case search using embedding vectors
    - Past case context for better insights
    """

    def __init__(self):
        self.llm = LLMService()
        self.embedding_service = get_embedding_service()

    def execute(self, signals: list[dict], context: dict) -> str:
        """
        Execute insight generation stage.

        Args:
            signals: List of validated signal dicts
            context: Unified context from ContextPipeline

        Returns:
            Generated insight/briefing string
        """
        corp_id = context.get("corp_id", "")
        corp_name = context.get("corp_name", "")

        logger.info(f"INSIGHT stage starting for corp_id={corp_id}")

        # Handle no signals case
        if not signals:
            insight = self._generate_no_signals_insight(corp_name)
            logger.info("INSIGHT stage completed (no signals)")
            return insight

        # Find similar past cases for context
        similar_cases = []
        if self.embedding_service.is_available:
            try:
                similar_cases = self._find_similar_cases(signals)
                logger.info(f"Found {len(similar_cases)} similar past cases")
            except Exception as e:
                logger.warning(f"Similar case search failed (non-fatal): {e}")

        try:
            insight = self._generate_insight(signals, context, similar_cases)
            logger.info(f"INSIGHT stage completed: {len(insight)} chars")
            return insight

        except AllProvidersFailedError as e:
            logger.error(f"LLM failed for insight generation: {e}")
            return self._generate_fallback_insight(signals, corp_name)

        except Exception as e:
            logger.error(f"Insight generation failed: {e}")
            return self._generate_fallback_insight(signals, corp_name)

    def _generate_insight(
        self,
        signals: list[dict],
        context: dict,
        similar_cases: list[dict] = None,
    ) -> str:
        """Generate insight using LLM with similar case context."""
        # Build signal summary for prompt
        signal_summary = self._build_signal_summary(signals)

        # Build similar cases summary
        similar_cases_summary = ""
        if similar_cases:
            similar_cases_summary = self._build_similar_cases_summary(similar_cases)

        user_prompt = INSIGHT_GENERATION_PROMPT.format(
            corp_name=context.get("corp_name", ""),
            industry_code=context.get("industry_code", ""),
            industry_name=context.get("industry_name", ""),
            signal_count=len(signals),
            signals_summary=signal_summary,
        )

        # Add similar cases to prompt if available
        if similar_cases_summary:
            user_prompt += f"\n\n### ìœ ì‚¬ ê³¼ê±° ì¼€ì´ìŠ¤ ì°¸ê³ \n{similar_cases_summary}"

        messages = [
            {
                "role": "system",
                "content": (
                    "You are a senior corporate analyst providing executive briefings. "
                    "Generate concise, actionable insights in Korean. "
                    "IMPORTANT: Cover both RISK and OPPORTUNITY factors with equal emphasis. "
                    "Opportunities like revenue growth, new products, factory expansion, technology investment "
                    "are valuable signals for banks to identify credit expansion opportunities. "
                    "Use probabilistic language: '~ë¡œ ì¶”ì •ë¨', '~ê°€ëŠ¥ì„± ìˆìŒ', 'ê²€í†  ê¶Œê³ '. "
                    "Avoid definitive statements like 'ë°˜ë“œì‹œ', 'ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”'. "
                    "If similar past cases are provided, reference them to provide historical context."
                ),
            },
            {
                "role": "user",
                "content": user_prompt,
            },
        ]

        # Use call_with_fallback for text response
        insight = self.llm.call_with_fallback(
            messages=messages,
            temperature=0.3,
            max_tokens=1000,
        )

        return insight.strip()

    def _find_similar_cases(
        self,
        signals: list[dict],
        limit: int = 5,
        similarity_threshold: float = 0.7,
    ) -> list[dict]:
        """
        Find similar past cases using embedding similarity.

        Args:
            signals: Current signals to find similar cases for
            limit: Maximum number of similar cases to return
            similarity_threshold: Minimum similarity score (0-1)

        Returns:
            List of similar case dicts with similarity scores
        """
        if not signals:
            return []

        # Use the most significant signal for case search
        # (typically HIGH impact or first signal)
        high_impact = [s for s in signals if s.get("impact_strength") == "HIGH"]
        target_signal = high_impact[0] if high_impact else signals[0]

        # Generate embedding for target signal
        combined_text = f"""
Signal Type: {target_signal.get('signal_type', '')}
Event Type: {target_signal.get('event_type', '')}
Title: {target_signal.get('title', '')}
Summary: {target_signal.get('summary', '')}
""".strip()

        try:
            embedding = self.embedding_service.embed_text(combined_text)
            if not embedding:
                return []

            # Query similar cases from database
            embedding_str = "[" + ",".join(str(x) for x in embedding) + "]"

            with get_sync_db() as db:
                # Use the helper function from migration
                result = db.execute(
                    text("""
                        SELECT
                            case_id,
                            corp_id,
                            industry_code,
                            signal_type,
                            event_type,
                            summary,
                            1 - (embedding <=> :embedding::vector) AS similarity
                        FROM rkyc_case_index
                        WHERE embedding IS NOT NULL
                          AND 1 - (embedding <=> :embedding::vector) >= :threshold
                        ORDER BY embedding <=> :embedding::vector
                        LIMIT :limit
                    """),
                    {
                        "embedding": embedding_str,
                        "threshold": similarity_threshold,
                        "limit": limit,
                    }
                )

                cases = []
                for row in result:
                    cases.append({
                        "case_id": str(row.case_id),
                        "corp_id": row.corp_id,
                        "industry_code": row.industry_code,
                        "signal_type": row.signal_type,
                        "event_type": row.event_type,
                        "summary": row.summary,
                        "similarity": round(row.similarity, 3),
                    })

                return cases

        except EmbeddingError as e:
            logger.warning(f"Embedding generation failed for case search: {e}")
            return []
        except Exception as e:
            logger.warning(f"Similar case search query failed: {e}")
            return []

    def _build_similar_cases_summary(self, cases: list[dict]) -> str:
        """Build summary text for similar cases."""
        if not cases:
            return ""

        lines = []
        for i, case in enumerate(cases, 1):
            similarity_pct = int(case.get("similarity", 0) * 100)
            lines.append(
                f"{i}. [{case.get('signal_type', 'N/A')}] {case.get('event_type', 'N/A')} "
                f"(ìœ ì‚¬ë„ {similarity_pct}%)\n"
                f"   - ì—…ì¢…: {case.get('industry_code', 'N/A')}\n"
                f"   - ìš”ì•½: {case.get('summary', 'N/A')[:100]}..."
            )

        return "\n".join(lines)

    def _build_signal_summary(self, signals: list[dict]) -> str:
        """Build signal summary for LLM prompt."""
        lines = []

        # Group by impact direction
        risk_signals = [s for s in signals if s.get("impact_direction") == "RISK"]
        opp_signals = [s for s in signals if s.get("impact_direction") == "OPPORTUNITY"]
        neutral_signals = [s for s in signals if s.get("impact_direction") == "NEUTRAL"]

        # OPPORTUNITY ì‹œê·¸ë„ì„ ë¨¼ì € í‘œì‹œ (ê¸°íšŒ ìš”ì¸ ê°•ì¡°)
        if opp_signals:
            lines.append(f"## ğŸš€ ê¸°íšŒ ì‹œê·¸ë„ ({len(opp_signals)}ê±´) - ì„±ì¥/íˆ¬ì/ìˆ˜ìµ ê°œì„  ê¸°íšŒ")
            for s in opp_signals:
                strength = s.get("impact_strength", "MED")
                event_type = s.get("event_type", "")
                opp_category = self._categorize_opportunity(event_type, s.get("title", ""), s.get("summary", ""))
                lines.append(f"- [{strength}] [{opp_category}] {s.get('title', '')}: {s.get('summary', '')[:100]}")

        if risk_signals:
            lines.append(f"\n## âš ï¸ ë¦¬ìŠ¤í¬ ì‹œê·¸ë„ ({len(risk_signals)}ê±´)")
            for s in risk_signals:
                strength = s.get("impact_strength", "MED")
                lines.append(f"- [{strength}] {s.get('title', '')}: {s.get('summary', '')[:100]}")

        if neutral_signals:
            lines.append(f"\n## ğŸ“‹ ì°¸ê³  ì‹œê·¸ë„ ({len(neutral_signals)}ê±´)")
            for s in neutral_signals:
                lines.append(f"- {s.get('title', '')}: {s.get('summary', '')[:100]}")

        return "\n".join(lines)

    def _categorize_opportunity(self, event_type: str, title: str, summary: str) -> str:
        """Categorize opportunity signal for better context."""
        text = f"{title} {summary}".lower()

        # ì¹´í…Œê³ ë¦¬ ë§¤í•‘
        if any(kw in text for kw in ["ë§¤ì¶œ", "ì‹¤ì ", "ì˜ì—…ì´ìµ", "ìˆœì´ìµ", "í‘ì", "ìˆ˜ìµ"]):
            return "ì‹¤ì ê°œì„ "
        elif any(kw in text for kw in ["ê³µì¥", "ì¦ì„¤", "ì„¤ë¹„", "íˆ¬ì", "í™•ì¥", "ì‹ ê·œ ì‚¬ì—…ì¥"]):
            return "ì„±ì¥íˆ¬ì"
        elif any(kw in text for kw in ["ì‹ ì œí’ˆ", "ì‹ ê¸°ìˆ ", "íŠ¹í—ˆ", "ê°œë°œ", "í˜ì‹ ", "r&d"]):
            return "ê¸°ìˆ í˜ì‹ "
        elif any(kw in text for kw in ["ìˆ˜ì£¼", "ê³„ì•½", "ê³ ê°", "ì‹œì¥", "í•´ì™¸", "ì§„ì¶œ"]):
            return "ì‹œì¥í™•ëŒ€"
        elif any(kw in text for kw in ["ë¶€ì±„", "ìœ ë™ì„±", "ì¬ë¬´", "ì‹ ìš©ë“±ê¸‰", "ê±´ì „ì„±"]):
            return "ì¬ë¬´ê°œì„ "
        elif any(kw in text for kw in ["ì •ì±…", "ì§€ì›", "ë³´ì¡°ê¸ˆ", "ì„¸ì œ", "ê·œì œ ì™„í™”"]):
            return "ì •ì±…ìˆ˜í˜œ"
        elif any(kw in text for kw in ["ë‹´ë³´", "ìì‚°", "ë¶€ë™ì‚°", "íŠ¹í—ˆ ê°€ì¹˜"]):
            return "ë‹´ë³´ê°•í™”"
        elif any(kw in text for kw in ["ì¸ìˆ˜", "í•©ë³‘", "ì œíœ´", "íŒŒíŠ¸ë„ˆ", "í•©ì‘"]):
            return "ì „ëµì œíœ´"
        elif any(kw in text for kw in ["esg", "í™˜ê²½", "ì§€ë°°êµ¬ì¡°", "ì§€ì†ê°€ëŠ¥"]):
            return "ESGê°œì„ "
        else:
            return "ê¸°íšŒìš”ì¸"

    def _generate_no_signals_insight(self, corp_name: str) -> str:
        """Generate insight when no signals detected."""
        return (
            f"{corp_name}ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼, ìƒˆë¡œìš´ ì‹œê·¸ë„ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
            "í˜„ì¬ ê¸°ì¤€ìœ¼ë¡œ íŠ¹ë³„í•œ ë¦¬ìŠ¤í¬ ìš”ì¸ ë° ê¸°íšŒ ìš”ì¸ì€ ê´€ì°°ë˜ì§€ ì•Šìœ¼ë‚˜, "
            "ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ì´ ê¶Œê³ ë©ë‹ˆë‹¤."
        )

    def _generate_fallback_insight(self, signals: list[dict], corp_name: str) -> str:
        """Generate basic insight without LLM (fallback)."""
        risk_count = sum(1 for s in signals if s.get("impact_direction") == "RISK")
        opp_count = sum(1 for s in signals if s.get("impact_direction") == "OPPORTUNITY")
        high_count = sum(1 for s in signals if s.get("impact_strength") == "HIGH")

        insight_parts = [f"{corp_name}ì— ëŒ€í•´ {len(signals)}ê°œì˜ ì‹œê·¸ë„ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤."]

        # ê¸°íšŒ ì‹œê·¸ë„ì„ ë¨¼ì € ì–¸ê¸‰ (ê¸ì •ì  ìš”ì¸ ê°•ì¡°)
        if opp_count > 0:
            insight_parts.append(f"ê¸°íšŒ ì‹œê·¸ë„ {opp_count}ê±´ (ì„±ì¥/íˆ¬ì/ì‹¤ì ê°œì„  ê¸°íšŒ)")
        if risk_count > 0:
            insight_parts.append(f"ë¦¬ìŠ¤í¬ ì‹œê·¸ë„ {risk_count}ê±´")
        if high_count > 0:
            insight_parts.append(f"(HIGH ê°•ë„ {high_count}ê±´ í¬í•¨)")

        # ê¸°íšŒ ì‹œê·¸ë„ì´ ìˆìœ¼ë©´ ì—¬ì‹  í™•ëŒ€ ê¸°íšŒ ì–¸ê¸‰
        if opp_count > 0:
            insight_parts.append("ê¸°íšŒ ì‹œê·¸ë„ì— ëŒ€í•´ì„œëŠ” ì—¬ì‹  í™•ëŒ€ ë° ì‹ ê·œ ìƒí’ˆ ì œì•ˆ ê²€í† ê°€ ê¶Œê³ ë©ë‹ˆë‹¤.")

        insight_parts.append("ìƒì„¸ ë‚´ìš©ì€ ì‹œê·¸ë„ ëª©ë¡ì„ ì°¸ì¡°í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")

        return " ".join(insight_parts)
